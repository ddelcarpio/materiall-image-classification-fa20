{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I did some research and I'll put what I find here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a bunch of pre-trained neural networks out there, but the most popular/accurate is VGG-16. Here's some code from an interesting website listed below. I'll paste their code/explanations here, and we can definitely mess with it to fit our needs.\n",
    "https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WEBSITE CODE VERSION ###\n",
    "### DO NOT RUN, JUST TO SEE GENERAL IMPLEMENTATION ###\n",
    "\n",
    "# We will be using only the basic models, with changes made only to the final layer.\n",
    "# This is because this is just a binary classification problem while these models \n",
    "# are built to handle up to 1000 classes.\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')\n",
    "\n",
    "# Since we don’t have to train all the layers, we make them non_trainable:\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# We will then build the last fully-connected layer. I have just used the basic settings, \n",
    "# but feel free to experiment with different values of dropout, and different Optimisers \n",
    "# and activation functions.\n",
    "\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "\n",
    "\n",
    "# We will now build the final model based on the training and validation sets we created earlier.\n",
    "# Please note to use the original directories itself instead of the augmented datasets I have used below. \n",
    "# I have used just 10 epochs, but you can also increase them to get better results:\n",
    "\n",
    "\n",
    "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)\n",
    "\n",
    "\n",
    "# Awesome! As you can see, we were able to achieve a validation Accuracy of 93% with just 10 epochs \n",
    "# and without any major changes to the model. This is where we realize how powerful transfer learning \n",
    "# is and how useful pre-trained models for image classification can be. A caveat here though – VGG16 \n",
    "# takes up a long time to train compared to other models and this can be a disadvantage when we are \n",
    "# dealing with huge datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardest part is going to be to get the images in the right format for the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
